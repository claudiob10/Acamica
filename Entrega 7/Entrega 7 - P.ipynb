{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto 7: Deploy de sistema de recomendación con Watson\n",
    "\n",
    "En este proyecto llevaremos a cabo la puesta en producción del modelo entrenado en el proyecto 5. Es decir, lo subirmos la nube de IBM y utilizando llamados a la API de Watson tendremos acceso a él para realizar predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sklearn\n",
    "from sklearn.datasets import load_files\n",
    "#moviedir = r'./dataset/movie_reviews' \n",
    "moviedir = 'C://Users//tnlocaladmin//OneDrive//Documentos//DS//Proyectos//Entrega 5//dataset//movie_reviews'\n",
    "movie_reviews = load_files(moviedir, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    movie_reviews.data, movie_reviews.target, test_size = 0.20, stratify=movie_reviews.target, random_state = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "eclf = joblib.load('sentiment.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IBM Watson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) Cargá** la biblioteca `WatsonMachineLearningAPIClient`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install watson-machine-learning-client\n",
    "#!Pip install --upgrade watson-developer-cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from watson_machine_learning_client import WatsonMachineLearningAPIClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Creá** variable con las credenciales que necesita `Watson`. Ellas son: `url, access_key, username, password e instance_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "cred = {\n",
    "  \"apikey\": \"PM9-fU8i8gQlsEUwRNYiw65eI_DUduREHg7QZrqJPKWL\",\n",
    "  \"iam_apikey_description\": \"Auto-generated for key 56d1aa85-5617-432a-b344-629c57617073\",\n",
    "  \"iam_apikey_name\": \"Service credentials-1\",\n",
    "  \"iam_role_crn\": \"crn:v1:bluemix:public:iam::::serviceRole:Manager\",\n",
    "  \"iam_serviceid_crn\": \"crn:v1:bluemix:public:iam-identity::a/6e95f0bb93b1425eb5b2b56281dd121e::serviceid:ServiceId-91816014-88ec-4e06-89e7-77547f385f84\",\n",
    "  \"instance_id\": \"6fe030c5-dc7a-4365-90ae-0ef5ae8f047e\",\n",
    "  \"password\": \"f1e9adbd-ee10-42be-8081-648d0eb5db29\",\n",
    "  \"url\": \"https://us-south.ml.cloud.ibm.com\",\n",
    "  \"username\": \"56d1aa85-5617-432a-b344-629c57617073\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) Declará** la variable `client` y guardá en ella al objeto `WatsonMachineLearningAPIClient` con las credenciales como parámetro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "cliente = WatsonMachineLearningAPIClient(cred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4) Creá** una variable que guarde las propiedades del modelo. Datos del autor y nombre del proyecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_props = {cliente.repository.ModelMetaNames.AUTHOR_NAME: \"Pablo Espinosa\",\n",
    "                        cliente.repository.ModelMetaNames.NAME: \"Procesamiento de Lenguaje Natural\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5) Hacé** un pipeline que contenga como primer paso a un `TfidfVectorizer` y como segundo paso, al mejor modelo que hayas obtenido en el proyecto 5. **Entrená** con este pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    movie_reviews.data, movie_reviews.target, test_size = 0.20, stratify=movie_reviews.target, random_state = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('tfidfvectorizer', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_i...rs=500, random_state=0))],\n",
       "         flatten_transform=None, n_jobs=1, voting='hard', weights=None))])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stops=set(stopwords.words('english'))\n",
    "\n",
    "vect = TfidfVectorizer(stop_words=stops, tokenizer = nltk.word_tokenize)\n",
    "\n",
    "pipeline = make_pipeline(vect, eclf)\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6) Subí** al modelo a IBM Cloud usando `client.repository.store_model` con los parámetros correctos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "published_model = cliente.repository.store_model(model=pipeline, \n",
    "                                                meta_props=model_props, \n",
    "                                                training_data=X_train, \n",
    "                                                training_target=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7) Obtené** el `uid` del modelo y guardalo en una variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "published_model_uid = cliente.repository.get_model_uid(published_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------  ---------------------------------  ------------------------  -----------------\n",
      "GUID                                  NAME                               CREATED                   FRAMEWORK\n",
      "c5b346b5-a1f6-45a2-bdbd-5bebfd7526d5  Procesamiento de Lenguaje Natural  2019-06-05T20:02:32.918Z  scikit-learn-0.19\n",
      "5019ace4-7ac7-4c61-bf19-f82e64066e72  Procesamiento de Lenguaje Natural  2019-06-05T19:54:02.765Z  scikit-learn-0.19\n",
      "98c1ce44-778d-4611-9724-7272eb5030de  Procesamiento de Lenguaje Natural  2019-06-05T19:50:24.369Z  scikit-learn-0.19\n",
      "ffa2b500-c9e0-4fff-954f-90795ab03828  Procesamiento de Lenguaje Natural  2019-06-05T19:33:14.315Z  scikit-learn-0.19\n",
      "761bb66e-bc10-443f-bbcc-f98f02bf6e39  Procesamiento de Lenguaje Natural  2019-06-05T18:58:43.886Z  scikit-learn-0.19\n",
      "------------------------------------  ---------------------------------  ------------------------  -----------------\n"
     ]
    }
   ],
   "source": [
    "models_details = cliente.repository.list_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8) Cargá** el modelo basado en su `uid` y utilizalo para realizar la predicción sobre el conjunto de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = cliente.repository.load(published_model_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = loaded_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9) Mostrar** el `classification_report` obtenido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc score:  0.8475\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.91      0.86       200\n",
      "          1       0.89      0.79      0.84       200\n",
      "\n",
      "avg / total       0.85      0.85      0.85       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"roc_auc score: \", roc_auc_score(y_test, test_predictions))\n",
    "print(classification_report(y_test, test_predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
